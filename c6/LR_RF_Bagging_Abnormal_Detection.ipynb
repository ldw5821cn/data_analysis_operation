{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#基于LR,RF,Bagging概率投票组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liudawei/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/liudawei/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/liudawei/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/liudawei/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/liudawei/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/liudawei/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/liudawei/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/Users/liudawei/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer #数值分类转整数分类库\n",
    "from imblearn.over_sampling import SMOTE #过抽样处理库SMOTE\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score #导入交叉验证库\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, BaggingClassifier #三种集成分类和投票方法库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据审查和预处理函数\n",
    "# 基本状态查看\n",
    "def set_summary(df):\n",
    "    '''\n",
    "    查看数据集后2条数据、数据类型、描述性统计\n",
    "    :param df: 数据框\n",
    "    :return: 无\n",
    "    '''\n",
    "    print ('{:*^60}'.format('Data overview:'))\n",
    "    print (df.tail(2))  # 打印原始数据后2条\n",
    "    print ('{:*^60}'.format('Data dtypes:'))\n",
    "    print (df.dtypes)  # 打印数据类型\n",
    "    print ('{:*^60}'.format('Data DESC:'))\n",
    "    print (df.describe().round(2).T)  # 打印原始数据基本描述性信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 缺失值审查\n",
    "def na_summary(df):\n",
    "    '''\n",
    "    查看数据集的缺失数据列、行记录数\n",
    "    :param df: 数据框\n",
    "    :return: 无\n",
    "    '''\n",
    "    na_cols = df.isnull().any(axis=0)  # 查看每一列是否具有缺失值\n",
    "    print ('{:*^60}'.format('NA Cols:'))\n",
    "    print (na_cols)  # 查看具有缺失值的列\n",
    "    na_lines = df.isnull().any(axis=1)  # 查看每一行是否具有缺失值\n",
    "    print ('Total number of NA lines is: {0}'.format(na_lines.sum()))  # 查看具有缺失值的行总记录数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类样本均衡审查\n",
    "def label_samples_summary(df):\n",
    "    '''\n",
    "    查看每个类的样本量分布\n",
    "    :param df: 数据框\n",
    "    :return: 无\n",
    "    '''\n",
    "    print ('{:*^60}'.format('Labesl samples count:'))\n",
    "    print (df.ix[:, 1].groupby(df.ix[:, -1]).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 字符串分类转整数分类\n",
    "def str2int(set, convert_object, unique_object, training=True):\n",
    "    '''\n",
    "    用于将分类变量中的字符串转换为数值索引分类\n",
    "    :param set: 数据集\n",
    "    :param convert_object:  DictVectorizer转换对象，当training为True时为空；当training为False时则使用从训练阶段得到的对象\n",
    "    :param unique_object: 唯一值列表，当training为True时为空；当training为False时则使用从训练阶段得到的唯一值列表\n",
    "    :param training: 是否为训练阶段\n",
    "    :return: 训练阶段返回model_dvtransform,unique_list,traing_part_data；预测应用阶段返回predict_part_data\n",
    "    '''\n",
    "    convert_cols = ['cat', 'attribution', 'pro_id', 'pro_brand', 'order_source', 'pay_type', 'use_id',\n",
    "                    'city']  # 定义要转换的列\n",
    "    final_convert_matrix = set[convert_cols]  # 获得要转换的数据集合\n",
    "    lines = set.shape[0]  # 获得总记录数\n",
    "    dict_list = []  # 总空列表，用于存放字符串与对应索引组成的字典\n",
    "    if training == True:  # 如果是训练阶段\n",
    "        unique_list = []  # 总唯一值列表，用于存储每个列的唯一值列表\n",
    "        for col_name in convert_cols:  # 循环读取每个列名\n",
    "            cols_unqiue_value = set[col_name].unique().tolist()  # 获取列的唯一值列表\n",
    "            unique_list.append(cols_unqiue_value)  # 将唯一值列表追加到总列表\n",
    "        for line_index in range(lines):  # 读取每行索引\n",
    "            each_record = final_convert_matrix.iloc[line_index]  # 获得每行数据，是一个Series\n",
    "            for each_index, each_data in enumerate(each_record):  # 读取Series每行对应的索引值\n",
    "                list_value = unique_list[each_index]  # 读取该行索引对应到总唯一值列表列索引下的数据(其实是相当于原来的列做了转置成了行，目的是查找唯一值在列表中的位置)\n",
    "                each_record[each_index] = list_value.index(each_data)  # 获得每个值对应到总唯一值列表中的索引\n",
    "            each_dict = dict(zip(convert_cols, each_record))  # 将每个值和对应的索引组合字典\n",
    "            dict_list.append(each_dict)  # 将字典追加到总列表\n",
    "        model_dvtransform = DictVectorizer(sparse=False, dtype=np.int64)  # 建立转换模型对象\n",
    "        model_dvtransform.fit(dict_list)  # 应用分类转换训练\n",
    "        traing_part_data = model_dvtransform.transform(dict_list)  # 转换训练集\n",
    "        return model_dvtransform, unique_list, traing_part_data\n",
    "    else:  # 如果是预测阶段\n",
    "        for line_index in range(lines):  # 读取每行索引\n",
    "            each_record = final_convert_matrix.iloc[line_index]  # 获得每行数据，是一个Series\n",
    "            for each_index, each_data in enumerate(each_record):  # 读取Series每行对应的索引值\n",
    "                list_value = unique_object[each_index]  # 读取该行索引对应到总唯一值列表列索引下的数据(其实是相当于原来的列做了转置成了行，目的是查找唯一值在列表中的位置)\n",
    "                each_record[each_index] = list_value.index(each_data)  # 获得每个值对应到总唯一值列表中的索引\n",
    "            each_dict = dict(zip(convert_cols, each_record))  # 将每个值和对应的索引组合字典\n",
    "            dict_list.append(each_dict)  # 将字典追加到总列表\n",
    "        predict_part_data = convert_object.transform(dict_list)  # 转换预测集\n",
    "        return predict_part_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 时间属性拓展\n",
    "def datetime2int(set):\n",
    "    '''\n",
    "    将日期和时间数据拓展出其他属性，例如星期几、周几、小时、分钟等。\n",
    "    :param set: 数据集\n",
    "    :return: 拓展后的属性矩阵\n",
    "    '''\n",
    "    date_set = map(lambda dates: pd.datetime.strptime(dates, '%Y-%m-%d'),\n",
    "                   set['order_date'])  # 将set中的order_date列转换为特定日期格式\n",
    "    weekday_data = map(lambda data: data.weekday(), date_set)  # 周几\n",
    "    daysinmonth_data = map(lambda data: data.day, date_set)  # 当月几号\n",
    "    month_data = map(lambda data: data.month, date_set)  # 月份\n",
    "\n",
    "    time_set = map(lambda times: pd.datetime.strptime(times, '%H:%M:%S'),\n",
    "                   set['order_time'])  # 将set中的order_time列转换为特定时间格式\n",
    "    second_data = map(lambda data: data.second, time_set)  # 秒\n",
    "    minute_data = map(lambda data: data.minute, time_set)  # 分钟\n",
    "    hour_data = map(lambda data: data.hour, time_set)  # 小时\n",
    "#     weekday_data = list(weekday_data)\n",
    "#     daysinmonth_data = list(daysinmonth_data)\n",
    "#     month_data = list(month_data)\n",
    "#     second_data = list(second_data)\n",
    "#     minute_data = list(minute_data)\n",
    "#     hour_data = list(hour_data)\n",
    "    final_set = []  # 列表，用于将上述拓展属性组合起来\n",
    "    final_set.extend((weekday_data, daysinmonth_data, month_data, second_data, minute_data, hour_data))  # 将属性列表批量组合\n",
    "    #final_set.extend((weekday_data, daysinmonth_data, month_data, second_data))  # 将属性列表批量组合\n",
    "    final_matrix = np.array(final_set).T  # 转换为矩阵并转置\n",
    "    return final_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 样本均衡\n",
    "def sample_balance(X, y):\n",
    "    '''\n",
    "    使用SMOTE方法对不均衡样本做过抽样处理\n",
    "    :param X: 输入特征变量X\n",
    "    :param y: 目标变量y\n",
    "    :return: 均衡后的X和y\n",
    "    '''\n",
    "    model_smote = SMOTE()  # 建立SMOTE模型对象\n",
    "    x_smote_resampled, y_smote_resampled = model_smote.fit_sample(X, y)  # 输入数据并作过抽样处理\n",
    "    return x_smote_resampled, y_smote_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据应用\n",
    "# 定义特殊字段数据格式\n",
    "dtypes = {'order_id': np.object,\n",
    "          'pro_id': np.object,\n",
    "          'use_id': np.object}\n",
    "raw_data = pd.read_table('abnormal_orders.txt', delimiter=',', dtype=dtypes)  # 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************Data overview:***********************\n",
      "          order_id  order_date order_time       cat attribution      pro_id  \\\n",
      "134188  4285770012  2013-09-19   23:55:06      家居日用          GO  1000335947   \n",
      "134189  4285770056  2013-05-20   23:58:59  生活电器厨卫电器          GO  1000009280   \n",
      "\n",
      "       pro_brand  total_money  total_quantity order_source pay_type  \\\n",
      "134188       炊大师         79.0               1           抢购     合并支付   \n",
      "134189        海尔        799.0               1           抢购     合并支付   \n",
      "\n",
      "            use_id city  abnormal_label  \n",
      "134188      shukun  东莞市               0  \n",
      "134189  544975322_  海口市               0  \n",
      "************************Data dtypes:************************\n",
      "order_id           object\n",
      "order_date         object\n",
      "order_time         object\n",
      "cat                object\n",
      "attribution        object\n",
      "pro_id             object\n",
      "pro_brand          object\n",
      "total_money       float64\n",
      "total_quantity      int64\n",
      "order_source       object\n",
      "pay_type           object\n",
      "use_id             object\n",
      "city               object\n",
      "abnormal_label      int64\n",
      "dtype: object\n",
      "*************************Data DESC:*************************\n",
      "                   count    mean      std  min   25%   50%    75%       max\n",
      "total_money     134189.0  660.11  2901.21  0.5  29.0  98.4  372.0  766000.0\n",
      "total_quantity  134190.0    1.20     3.23  1.0   1.0   1.0    1.0    1000.0\n",
      "abnormal_label  134190.0    0.21     0.41  0.0   0.0   0.0    0.0       1.0\n",
      "**************************NA Cols:**************************\n",
      "order_id          False\n",
      "order_date        False\n",
      "order_time        False\n",
      "cat                True\n",
      "attribution       False\n",
      "pro_id            False\n",
      "pro_brand          True\n",
      "total_money        True\n",
      "total_quantity    False\n",
      "order_source      False\n",
      "pay_type          False\n",
      "use_id            False\n",
      "city               True\n",
      "abnormal_label    False\n",
      "dtype: bool\n",
      "Total number of NA lines is: 1429\n",
      "*******************Labesl samples count:********************\n",
      "abnormal_label\n",
      "0    105733\n",
      "1     28457\n",
      "Name: order_date, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liudawei/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# 数据审查\n",
    "set_summary(raw_data)  # 基本状态查看\n",
    "na_summary(raw_data)  # 缺失值审查\n",
    "label_samples_summary(raw_data)  # 类样本分布审查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liudawei/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "2\n",
      "2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e35f3c27c2f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime2int_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mcombine_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr2int_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime2int_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 合并转换后的分类和拓展后的日期数据集\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mconstant_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_raw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_money'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'total_quantity'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# 原始连续数据变量\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mX_combine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombine_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstant_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 再次合并数据集\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "# 数据预处理\n",
    "drop_na_set = raw_data.dropna()  # 丢弃带有NA值的数据行\n",
    "X_raw = drop_na_set.ix[:, 1:-1]  # 分割输入变量X，并丢弃订单ID列和最后一列目标变量\n",
    "y_raw = drop_na_set.ix[:, -1]  # 分割目标变量y\n",
    "model_dvtransform, unique_object, str2int_data = str2int(X_raw, None, None, training=True)  # 字符串分类转整数型分类\n",
    "datetime2int_data = datetime2int(X_raw)  # 拓展日期时间属性\n",
    "\n",
    "print(str2int_data.ndim)\n",
    "print(datetime2int_data.ndim)\n",
    "datetime2int_data = datetime2int_data[:,np.newaxis]\n",
    "print(str2int_data.ndim)\n",
    "print(datetime2int_data.ndim)\n",
    "\n",
    "combine_set = np.hstack((str2int_data, datetime2int_data)) # 合并转换后的分类和拓展后的日期数据集\n",
    "constant_set = X_raw[['total_money', 'total_quantity']]  # 原始连续数据变量\n",
    "X_combine = np.hstack((combine_set, constant_set))  # 再次合并数据集\n",
    "X, y = sample_balance(X_combine, y_raw)  # 样本均衡处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 组合分类模型交叉检验\n",
    "model_rf = RandomForestClassifier(n_estimators=20, random_state=0)  # 随机森林分类模型对象\n",
    "model_lr = LogisticRegression(random_state=0)  # 逻辑回归分类模型对象\n",
    "model_BagC = BaggingClassifier(n_estimators=20, random_state=0)  # Bagging分类模型对象\n",
    "estimators = [('randomforest', model_rf), ('Logistic', model_lr), ('bagging', model_BagC)]  # 建立组合评估器列表\n",
    "model_vot = VotingClassifier(estimators=estimators, voting='soft', weights=[0.9, 1.2, 1.1], n_jobs=-1)  # 建立组合评估模型\n",
    "cv = StratifiedKFold(8)  # 设置交叉检验方法\n",
    "cv_score = cross_val_score(model_vot, X, y, cv=cv)  # 交叉检验\n",
    "print ('{:*^60}'.format('Cross val socres:'))\n",
    "print (cv_score)  # 打印每次交叉检验得分\n",
    "print ('Mean scores is: %.2f' % cv_score.mean())  # 打印平均交叉检验得分\n",
    "model_vot.fit(X, y)  # 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新数据集做预测\n",
    "X_raw_data = pd.read_csv('new_abnormal_orders.csv', dtype=dtypes)  # 读取要预测的数据集\n",
    "X_raw_new = X_raw_data.ix[:, 1:]  # 分割输入变量X，并丢弃订单ID列\n",
    "str2int_data_new = str2int(X_raw_new, model_dvtransform, unique_object, training=False)  # 字符串分类转整数型分类\n",
    "datetime2int_data_new = datetime2int(X_raw_new)  # 日期时间转换\n",
    "combine_set_new = np.hstack((str2int_data_new, datetime2int_data_new))  # 合并转换后的分类和拓展后的日期数据集\n",
    "constant_set_new = X_raw_new[['total_money', 'total_quantity']]  # 原始连续数据变量\n",
    "X_combine_new = np.hstack((combine_set_new, constant_set_new))  # 再次合并数据集\n",
    "y_predict = model_vot.predict(X_combine_new)  # 预测结果\n",
    "print ('{:*^60}'.format('Predicted Labesls:'))\n",
    "print (y_predict)  # 打印预测值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

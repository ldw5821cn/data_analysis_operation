{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#基于AdaBoost的营销响应预测\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score # 导入交叉验证算法\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif #导入特征选择方法库\n",
    "from sklearn.ensemble import AdaBoostClassifier #导入集成算法\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本状态查看\n",
    "def set_summary(df):\n",
    "    '''\n",
    "    查看数据集的记录数、维度数、前2条数据、描述性统计和数据类型\n",
    "    :param df: 数据框\n",
    "    :return: 无\n",
    "    '''\n",
    "    print ('Data Overview')\n",
    "    print ('Records: {0}\\tDimension{1}'.format(df.shape[0], (df.shape[1] - 1)))  # 打印数据集X形状\n",
    "    print ('-' * 30)\n",
    "    print (df.head(2))  # 打印前2条数据\n",
    "    print ('-' * 30)\n",
    "    print ('Data DESC')\n",
    "    print (df.describe())  # 打印数据基本描述性信息\n",
    "    print ('Data Dtypes')\n",
    "    print (df.dtypes)  # 打印数据类型\n",
    "    print ('-' * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 缺失值审查\n",
    "def na_summary(df):\n",
    "    '''\n",
    "    查看数据集的缺失数据列、行记录数\n",
    "    :param df: 数据框\n",
    "    :return: 无\n",
    "    '''\n",
    "    na_cols = df.isnull().any(axis=0)  # 每一列是否具有缺失值\n",
    "    print ('NA Cols:')\n",
    "    print (na_cols)  # 查看具有缺失值的列\n",
    "    print ('-' * 30)\n",
    "    print ('valid records for each Cols:')\n",
    "    print (df.count())  # 查看每一列有效值（非NA）的记录数\n",
    "    print ('-' * 30)\n",
    "    na_lines = df.isnull().any(axis=1)  # 查看每一行是否具有缺失值\n",
    "    print ('Total number of NA lines is: {0}'.format(na_lines.sum()))  # 查看具有缺失值的行总记录数\n",
    "    print ('-' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 类样本均衡审查\n",
    "def label_summary(df):\n",
    "    '''\n",
    "    查看每个类的样本量分布\n",
    "    :param df: 数据框\n",
    "    :return: 无\n",
    "    '''\n",
    "    print ('Labesl samples count:')\n",
    "    print (df['value_level'].groupby(df['response']).count())  # 以response为分类汇总维度对value_level列计数统计\n",
    "    print ('-' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "# 变量类型转换\n",
    "def type_con(df):\n",
    "    '''\n",
    "    转换目标列的数据为特定数据类型\n",
    "    :param df: 数据框\n",
    "    :return: 类型转换后的数据框\n",
    "    '''\n",
    "    var_list = {'edu': 'int32',\n",
    "                'user_level': 'int32',\n",
    "                'industry': 'int32',\n",
    "                'value_level': 'int32',\n",
    "                'act_level': 'int32',\n",
    "                'sex': 'int32',\n",
    "                'region': 'int32'\n",
    "                }  # 字典：定义要转换的列及其数据类型\n",
    "    for var, type in var_list.items():  # 循环读出列名和对应的数据类型\n",
    "        df[var] = df[var].astype(type)  # 数据类型转换\n",
    "    print ('Data Dtypes')\n",
    "    print (df.dtypes)  # 打印数据类型\n",
    "    print ('-' * 30)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NA值替换\n",
    "def na_replace(df):\n",
    "    '''\n",
    "    将数据集中的NA值使用自定义方法替换\n",
    "    :param df: 数据框\n",
    "    :return: NA值替换后的数据框\n",
    "    '''\n",
    "    na_rules = {'age': df['age'].mean(),\n",
    "                'total_pageviews': df['total_pageviews'].mean(),\n",
    "                'edu': df['edu'].median(),\n",
    "                'edu_ages': df['edu_ages'].median(),\n",
    "                'user_level': df['user_level'].median(),\n",
    "                'industry': df['user_level'].median(),\n",
    "                'act_level': df['act_level'].median(),\n",
    "                'sex': df['sex'].median(),\n",
    "                'red_money': df['red_money'].mean(),\n",
    "                'region': df['region'].median()\n",
    "                }  # 字典：定义各个列数据转换方法\n",
    "    df = df.fillna(na_rules)  # 使用指定方法填充缺失值\n",
    "    print ('Check NA exists:')\n",
    "    print (df.isnull().any().sum())  # 查找是否还有缺失值\n",
    "    print ('-' * 30)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标志转换\n",
    "def symbol_con(df, enc_object=None, train=True):\n",
    "    '''\n",
    "    将分类和顺序变量转换为二值化的标志变量\n",
    "    :param df: 数据框\n",
    "    :param enc_object: sklearn的标志转换对象，训练阶段设置默认值为None；预测阶段使用从训练阶段获得的转换对象\n",
    "    :param train: 是否为训练阶段的判断状态，训练阶段为True，预测阶段为False\n",
    "    :return: 标志转换后的数据框、标志转换对象（如果是训练阶段）\n",
    "    '''\n",
    "    convert_cols = ['edu', 'user_level', 'industry', 'value_level', 'act_level', 'sex', 'region']  # 选择要做标志转换的列名\n",
    "    df_con = df[convert_cols]  # 选择要做标志转换的数据\n",
    "    df_org = df[['age', 'total_pageviews', 'edu_ages', 'blue_money', 'red_money', 'work_hours']].values  # 设置不作标志转换的列\n",
    "    if train == True:  # 如果处于训练阶段\n",
    "        enc = OneHotEncoder()  # 建立标志转换模型对象\n",
    "        enc.fit(df_con)  # 训练模型\n",
    "        df_con_new = enc.transform(df_con).toarray()  # 转换数据并输出为数组格式\n",
    "        new_matrix = np.hstack((df_con_new, df_org))  # 将未转换的数据与转换后的数据合并\n",
    "        return new_matrix, enc\n",
    "    else:\n",
    "        df_con_new = enc_object.transform(df_con).toarray()  # 使用训练阶段获得的转换对象转换数据并输出为数组格式\n",
    "        new_matrix = np.hstack((df_con_new, df_org))  # 将未转换的数据与转换后的数据合并\n",
    "        return new_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得最佳模型参数\n",
    "def get_best_model(X, y):\n",
    "    '''\n",
    "    结合交叉检验得到不同参数下的分类模型结果\n",
    "    :param X: 输入X（特征变量）\n",
    "    :param y: 预测y（目标变量）\n",
    "    :return: 特征选择模型对象\n",
    "    '''\n",
    "    transform = SelectPercentile(f_classif, percentile=50)  # 使用f_classif方法选择特征最明显的50%数量的特征\n",
    "    model_adaboost = AdaBoostClassifier()  # 建立AdaBoostClassifier模型对象\n",
    "    model_pipe = Pipeline(steps=[('ANOVA', transform), ('model_adaboost', model_adaboost)])  # 建立由特征选择和分类模型构成的“管道”对象\n",
    "    cv = StratifiedKFold(5)  # 设置交叉检验次数\n",
    "    n_estimators = [20, 50, 80, 100]  # 设置模型参数列表\n",
    "    score_methods = ['accuracy', 'f1', 'precision', 'recall', 'roc_auc']  # 设置交叉检验指标\n",
    "    mean_list = list()  # 建立空列表用于存放不同参数方法、交叉检验评估指标的均值列表\n",
    "    std_list = list()  # 建立空列表用于存放不同参数方法、交叉检验评估指标的标准差列表\n",
    "    for parameter in n_estimators:  # 循环读出每个参数值\n",
    "        t1 = time.time()  # 记录训练开始的时间\n",
    "        score_list = list()  # 建立空列表用于存放不同交叉检验下各个评估指标的详细数据\n",
    "        print ('set parameters: %s' % parameter)  # 打印当前模型使用的参数\n",
    "        for score_method in score_methods:  # 循环读出每个交叉检验指标\n",
    "            model_pipe.set_params(model_adaboost__n_estimators=parameter)  # 通过“管道”设置分类模型参数\n",
    "            score_tmp = cross_val_score(model_pipe, X, y, scoring=score_method, cv=cv)  # 使用交叉检验计算指定指标的得分\n",
    "            score_list.append(score_tmp)  # 将交叉检验得分存储到列表\n",
    "        score_matrix = pd.DataFrame(np.array(score_list), index=score_methods)  # 将交叉检验详细数据转换为矩阵\n",
    "        score_mean = score_matrix.mean(axis=1).rename('mean')  # 计算每个评估指标的均值\n",
    "        score_std = score_matrix.std(axis=1).rename('std')  # 计算每个评估指标的标准差\n",
    "        score_pd = pd.concat([score_matrix, score_mean, score_std], axis=1)  # 将原始详细数据和均值、标准差合并\n",
    "        mean_list.append(score_mean)  # 将每个参数得到的各指标均值追加到列表\n",
    "        std_list.append(score_std)  # 将每个参数得到的各指标标准差追加到列表\n",
    "        print (score_pd.round(2))  # 打印每个参数得到的交叉检验指标数据，只保留2位小数\n",
    "        print ('-' * 60)\n",
    "        t2 = time.time()  # 计算每个参数下算法用时\n",
    "        tt = t2 - t1  # 计算时间间隔\n",
    "        print ('time: %s' % str(tt))  # 打印时间间隔\n",
    "    mean_matrix = np.array(mean_list).T  # 建立所有参数得到的交叉检验的均值矩阵\n",
    "    std_matrix = np.array(std_list).T  # 建立所有参数得到的交叉检验的标准差矩阵\n",
    "    mean_pd = pd.DataFrame(mean_matrix, index=score_methods, columns=n_estimators)  # 将均值矩阵转换为数据框\n",
    "    std_pd = pd.DataFrame(std_matrix, index=score_methods, columns=n_estimators)  # 将均值标准差转换为数据框\n",
    "    print ('Mean values for each parameter:')\n",
    "    print (mean_pd)  # 打印输出均值矩阵\n",
    "    print ('Std values for each parameter:')\n",
    "    print (std_pd)  # 打印输出标准差矩阵\n",
    "    print ('-' * 60)\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "# 数据应用\n",
    "# 加载数据集\n",
    "raw_data = pd.read_excel('order.xlsx', sheetname=0)  # 读出Excel的第一个sheet\n",
    "X = raw_data.drop('response', axis=1)  # 分割X\n",
    "y = raw_data['response']  # 分割y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Overview\n",
      "Records: 39999\tDimension13\n",
      "------------------------------\n",
      "    age  total_pageviews  edu  edu_ages  user_level  industry  value_level  \\\n",
      "0  39.0          77516.0  1.0      13.0         1.0       1.0            1   \n",
      "1  50.0          83311.0  1.0      13.0         2.0       2.0            2   \n",
      "\n",
      "   act_level  sex  blue_money  red_money  work_hours  region  response  \n",
      "0        1.0  1.0        2174        0.0          40     1.0         0  \n",
      "1        1.0  1.0           0        0.0          13     1.0         0  \n",
      "------------------------------\n",
      "Data DESC\n",
      "                age  total_pageviews           edu      edu_ages  \\\n",
      "count  39998.000000     3.999800e+04  39998.000000  39998.000000   \n",
      "mean      38.589654     1.895136e+05      2.511626     10.076754   \n",
      "std       13.663490     1.053109e+05      1.638110      2.573384   \n",
      "min       17.000000     1.228500e+04      1.000000      1.000000   \n",
      "25%       28.000000     1.175282e+05      2.000000      9.000000   \n",
      "50%       37.000000     1.783410e+05      2.000000     10.000000   \n",
      "75%       48.000000     2.372685e+05      2.000000     12.000000   \n",
      "max       90.000000     1.484705e+06     10.000000     16.000000   \n",
      "\n",
      "         user_level      industry   value_level     act_level           sex  \\\n",
      "count  39998.000000  39997.000000  39999.000000  39998.000000  39998.000000   \n",
      "mean       2.087004      5.677126      2.546289      1.221036      0.668083   \n",
      "std        1.260992      3.395948      1.443210      0.626618      0.470907   \n",
      "min        1.000000      1.000000      1.000000      1.000000      0.000000   \n",
      "25%        1.000000      3.000000      1.000000      1.000000      0.000000   \n",
      "50%        2.000000      5.000000      2.000000      1.000000      1.000000   \n",
      "75%        2.000000      8.000000      4.000000      1.000000      1.000000   \n",
      "max        7.000000     15.000000      6.000000      5.000000      1.000000   \n",
      "\n",
      "         blue_money     red_money    work_hours        region      response  \n",
      "count  39999.000000  39998.000000  39999.000000  39997.000000  39999.000000  \n",
      "mean    1089.142529     87.379394     40.442486      2.251519      0.239606  \n",
      "std     7491.275548    402.930350     12.376033      4.913482      0.426848  \n",
      "min        0.000000      0.000000      1.000000      1.000000      0.000000  \n",
      "25%        0.000000      0.000000     40.000000      1.000000      0.000000  \n",
      "50%        0.000000      0.000000     40.000000      1.000000      0.000000  \n",
      "75%        0.000000      0.000000     45.000000      1.000000      0.000000  \n",
      "max    99999.000000   4356.000000     99.000000     41.000000      1.000000  \n",
      "Data Dtypes\n",
      "age                float64\n",
      "total_pageviews    float64\n",
      "edu                float64\n",
      "edu_ages           float64\n",
      "user_level         float64\n",
      "industry           float64\n",
      "value_level          int64\n",
      "act_level          float64\n",
      "sex                float64\n",
      "blue_money           int64\n",
      "red_money          float64\n",
      "work_hours           int64\n",
      "region             float64\n",
      "response             int64\n",
      "dtype: object\n",
      "------------------------------------------------------------\n",
      "NA Cols:\n",
      "age                 True\n",
      "total_pageviews     True\n",
      "edu                 True\n",
      "edu_ages            True\n",
      "user_level          True\n",
      "industry            True\n",
      "value_level        False\n",
      "act_level           True\n",
      "sex                 True\n",
      "blue_money         False\n",
      "red_money           True\n",
      "work_hours         False\n",
      "region              True\n",
      "response           False\n",
      "dtype: bool\n",
      "------------------------------\n",
      "valid records for each Cols:\n",
      "age                39998\n",
      "total_pageviews    39998\n",
      "edu                39998\n",
      "edu_ages           39998\n",
      "user_level         39998\n",
      "industry           39997\n",
      "value_level        39999\n",
      "act_level          39998\n",
      "sex                39998\n",
      "blue_money         39999\n",
      "red_money          39998\n",
      "work_hours         39999\n",
      "region             39997\n",
      "response           39999\n",
      "dtype: int64\n",
      "------------------------------\n",
      "Total number of NA lines is: 12\n",
      "------------------------------\n",
      "Labesl samples count:\n",
      "response\n",
      "0    30415\n",
      "1     9584\n",
      "Name: value_level, dtype: int64\n",
      "------------------------------------------------------------\n",
      "Check NA exists:\n",
      "0\n",
      "------------------------------\n",
      "Data Dtypes\n",
      "age                float64\n",
      "total_pageviews    float64\n",
      "edu                  int32\n",
      "edu_ages           float64\n",
      "user_level           int32\n",
      "industry             int32\n",
      "value_level          int32\n",
      "act_level            int32\n",
      "sex                  int32\n",
      "blue_money           int64\n",
      "red_money          float64\n",
      "work_hours           int64\n",
      "region               int32\n",
      "dtype: object\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 数据审查和预处理\n",
    "set_summary(raw_data)  # 基本状态查看\n",
    "na_summary(raw_data)  # 缺失值审查\n",
    "label_summary(raw_data)  # 类样本均衡均衡审查\n",
    "X_t1 = na_replace(X)  # 替换缺失值\n",
    "X_t2 = type_con(X_t1)  # 数据类型转换\n",
    "X_new, enc = symbol_con(X_t2, enc_object=None, train=True)  # 将分类和顺序数据转换为标志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set parameters: 20\n",
      "              0     1     2     3     4  mean   std\n",
      "accuracy   0.85  0.85  0.86  0.86  0.86  0.85  0.01\n",
      "f1         0.66  0.64  0.66  0.66  0.66  0.66  0.01\n",
      "precision  0.72  0.74  0.76  0.78  0.77  0.75  0.02\n",
      "recall     0.60  0.57  0.59  0.58  0.57  0.58  0.01\n",
      "roc_auc    0.91  0.90  0.91  0.91  0.91  0.91  0.00\n",
      "------------------------------------------------------------\n",
      "time: 9.742232084274292\n",
      "set parameters: 50\n",
      "              0     1     2     3     4  mean   std\n",
      "accuracy   0.86  0.86  0.86  0.87  0.86  0.86  0.00\n",
      "f1         0.66  0.66  0.67  0.69  0.68  0.67  0.01\n",
      "precision  0.75  0.76  0.77  0.78  0.77  0.76  0.01\n",
      "recall     0.59  0.58  0.59  0.62  0.61  0.60  0.02\n",
      "roc_auc    0.91  0.91  0.91  0.92  0.92  0.91  0.00\n",
      "------------------------------------------------------------\n",
      "time: 20.814851999282837\n",
      "set parameters: 80\n",
      "              0     1     2     3     4  mean   std\n",
      "accuracy   0.86  0.86  0.86  0.87  0.86  0.86  0.00\n",
      "f1         0.67  0.67  0.68  0.70  0.68  0.68  0.01\n",
      "precision  0.76  0.77  0.77  0.79  0.76  0.77  0.01\n",
      "recall     0.60  0.59  0.61  0.62  0.62  0.61  0.01\n",
      "roc_auc    0.92  0.92  0.92  0.92  0.92  0.92  0.00\n",
      "------------------------------------------------------------\n",
      "time: 32.525413274765015\n",
      "set parameters: 100\n",
      "              0     1     2     3     4  mean   std\n",
      "accuracy   0.86  0.86  0.87  0.87  0.86  0.86  0.00\n",
      "f1         0.67  0.67  0.69  0.70  0.69  0.68  0.01\n",
      "precision  0.76  0.77  0.78  0.79  0.76  0.77  0.01\n",
      "recall     0.60  0.60  0.61  0.63  0.62  0.61  0.01\n",
      "roc_auc    0.92  0.92  0.92  0.92  0.92  0.92  0.00\n",
      "------------------------------------------------------------\n",
      "time: 40.2922899723053\n",
      "Mean values for each parameter:\n",
      "                20        50        80        100\n",
      "accuracy   0.853946  0.859922  0.862647  0.863672\n",
      "f1         0.656329  0.672173  0.679723  0.682772\n",
      "precision  0.753126  0.764994  0.770094  0.771560\n",
      "recall     0.582011  0.599542  0.608411  0.612376\n",
      "roc_auc    0.908324  0.914994  0.918613  0.919941\n",
      "Std values for each parameter:\n",
      "                20        50        80        100\n",
      "accuracy   0.005260  0.004636  0.004463  0.004834\n",
      "f1         0.009512  0.012836  0.011527  0.011929\n",
      "precision  0.023295  0.010208  0.011250  0.012753\n",
      "recall     0.013767  0.016128  0.013591  0.013184\n",
      "roc_auc    0.003201  0.002865  0.002629  0.002652\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=100, random_state=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 分类模型训练\n",
    "transform = get_best_model(X_new, y)  # 获得最佳分类模型参数信息\n",
    "transform.fit(X_new, y)  # 应用特征选择对象选择要参与建模的特征变量\n",
    "X_final = transform.transform(X_new)  # 获得具有显著性特征的特征变量\n",
    "final_model = AdaBoostClassifier(n_estimators=100)  # 从打印的参数均值和标准差信息中确定参数并建立分类模型对象\n",
    "final_model.fit(X_final, y)  # 训练模型  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Overview\n",
      "Records: 8843\tDimension12\n",
      "------------------------------\n",
      "   age  total_pageviews  edu  edu_ages  user_level  industry  value_level  \\\n",
      "0   61           243019   10         1         2.0       7.0            2   \n",
      "1   33           215596    4         5         2.0       7.0            2   \n",
      "\n",
      "   act_level  sex  blue_money  red_money  work_hours  region  \n",
      "0          1    1           0          0          40     1.0  \n",
      "1          5    1           0          0          40     6.0  \n",
      "------------------------------\n",
      "Data DESC\n",
      "               age  total_pageviews          edu     edu_ages   user_level  \\\n",
      "count  8843.000000     8.843000e+03  8843.000000  8843.000000  8841.000000   \n",
      "mean     38.884428     1.903636e+05     2.492141    10.083795     2.070015   \n",
      "std      13.917154     1.069146e+05     1.603766     2.560132     1.241608   \n",
      "min      17.000000     1.349200e+04     1.000000     1.000000     1.000000   \n",
      "25%      28.000000     1.177010e+05     2.000000     9.000000     1.000000   \n",
      "50%      37.000000     1.775960e+05     2.000000    10.000000     2.000000   \n",
      "75%      48.000000     2.395390e+05     2.000000    12.000000     2.000000   \n",
      "max      90.000000     1.490400e+06    10.000000    16.000000     7.000000   \n",
      "\n",
      "          industry  value_level    act_level          sex    blue_money  \\\n",
      "count  8841.000000  8843.000000  8843.000000  8843.000000   8843.000000   \n",
      "mean      5.737699     2.504128     1.216669     0.670248   1033.496438   \n",
      "std       3.416071     1.425389     0.621275     0.470150   7272.047201   \n",
      "min       1.000000     1.000000     1.000000     0.000000      0.000000   \n",
      "25%       3.000000     1.000000     1.000000     0.000000      0.000000   \n",
      "50%       5.000000     2.000000     1.000000     1.000000      0.000000   \n",
      "75%       8.000000     4.000000     1.000000     1.000000      0.000000   \n",
      "max      15.000000     6.000000     5.000000     1.000000  99999.000000   \n",
      "\n",
      "         red_money   work_hours       region  \n",
      "count  8843.000000  8843.000000  8838.000000  \n",
      "mean     88.068190    40.331449     2.332541  \n",
      "std     403.384021    12.461211     5.156087  \n",
      "min       0.000000     1.000000     1.000000  \n",
      "25%       0.000000    40.000000     1.000000  \n",
      "50%       0.000000    40.000000     1.000000  \n",
      "75%       0.000000    45.000000     1.000000  \n",
      "max    3770.000000    99.000000    40.000000  \n",
      "Data Dtypes\n",
      "age                  int64\n",
      "total_pageviews      int64\n",
      "edu                  int64\n",
      "edu_ages             int64\n",
      "user_level         float64\n",
      "industry           float64\n",
      "value_level          int64\n",
      "act_level            int64\n",
      "sex                  int64\n",
      "blue_money           int64\n",
      "red_money            int64\n",
      "work_hours           int64\n",
      "region             float64\n",
      "dtype: object\n",
      "------------------------------------------------------------\n",
      "NA Cols:\n",
      "age                False\n",
      "total_pageviews    False\n",
      "edu                False\n",
      "edu_ages           False\n",
      "user_level          True\n",
      "industry            True\n",
      "value_level        False\n",
      "act_level          False\n",
      "sex                False\n",
      "blue_money         False\n",
      "red_money          False\n",
      "work_hours         False\n",
      "region              True\n",
      "dtype: bool\n",
      "------------------------------\n",
      "valid records for each Cols:\n",
      "age                8843\n",
      "total_pageviews    8843\n",
      "edu                8843\n",
      "edu_ages           8843\n",
      "user_level         8841\n",
      "industry           8841\n",
      "value_level        8843\n",
      "act_level          8843\n",
      "sex                8843\n",
      "blue_money         8843\n",
      "red_money          8843\n",
      "work_hours         8843\n",
      "region             8838\n",
      "dtype: int64\n",
      "------------------------------\n",
      "Total number of NA lines is: 7\n",
      "------------------------------\n",
      "Check NA exists:\n",
      "0\n",
      "------------------------------\n",
      "Data Dtypes\n",
      "age                int64\n",
      "total_pageviews    int64\n",
      "edu                int32\n",
      "edu_ages           int64\n",
      "user_level         int32\n",
      "industry           int32\n",
      "value_level        int32\n",
      "act_level          int32\n",
      "sex                int32\n",
      "blue_money         int64\n",
      "red_money          int64\n",
      "work_hours         int64\n",
      "region             int32\n",
      "dtype: object\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 新数据集做预测\n",
    "new_data = pd.read_excel('order.xlsx', sheetname=1)  # 读取要预测的数据集\n",
    "final_reponse = new_data['final_response']  # 获取最终的目标变量值\n",
    "new_data = new_data.drop('final_response', axis=1)  # 获得预测的输入变量X\n",
    "set_summary(new_data)  # 基本状态查看\n",
    "na_summary(new_data)  # 缺失值审查\n",
    "new_X_t1 = na_replace(new_data)  # 替换缺失值\n",
    "new_X_t2 = type_con(new_X_t1)  # 数据类型转换\n",
    "new_X_t3 = symbol_con(new_X_t2, enc_object=enc, train=False)  # 将分类和顺序数据转换为标志\n",
    "new_X_final = transform.transform(new_X_t3)  # 对数据集做特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict info\n",
      "   age  total_pageviews  edu  edu_ages  user_level  industry  value_level  \\\n",
      "0   61           243019   10         1         2.0       7.0            2   \n",
      "1   33           215596    4         5         2.0       7.0            2   \n",
      "\n",
      "   act_level  sex  blue_money  red_money  work_hours  region  labels  \\\n",
      "0          1    1           0          0          40     1.0       0   \n",
      "1          5    1           0          0          40     6.0       0   \n",
      "\n",
      "       pro1      pro2  \n",
      "0  0.504053  0.495947  \n",
      "1  0.507486  0.492514  \n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 输出预测值以及预测概率\n",
    "predict_labels = pd.DataFrame(final_model.predict(new_X_final), columns=['labels'])  # 获得预测标签\n",
    "predict_labels_pro = pd.DataFrame(final_model.predict_proba(new_X_final), columns=['pro1', 'pro2'])  # 获得预测概率\n",
    "predict_pd = pd.concat((new_data, predict_labels, predict_labels_pro), axis=1)  # 将预测标签、预测数据和原始数据X合并\n",
    "print ('Predict info')\n",
    "print (predict_pd.head(2))  # 打印前2条结果\n",
    "print ('-' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将预测结果写入Excel\n",
    "writer = pd.ExcelWriter('order_predict_result.xlsx')  # 创建写入文件对象\n",
    "predict_pd.to_excel(writer, 'Sheet1')  # 将数据写入sheet1\n",
    "writer.save()  # 保存文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final accuracy: 0.8624901051679295\n"
     ]
    }
   ],
   "source": [
    "# 后续--与实际效果的比较\n",
    "print ('final accuracy: {0}'.format(accuracy_score(final_reponse, predict_labels)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
